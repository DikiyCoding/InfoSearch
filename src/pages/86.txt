Мозг, смысл и конец света / Хабр Все сервисы Хабра вчера в 15:48 Мозг, смысл и конец света , , , , Напомню предысторию. Меня зовут Алексей Редозубов и я занимаюсь созданием сильного искусственного интеллекта. Мой подход крутится вокруг контекстно-смысловой модели работы мозга. Об этом был цикл статей на хабре и много видео на Youtube. Сейчас я хочу рассказать об основах контекстно-смысловой модели и о недавних исследованиях, которые позволили взглянуть на эту модель с новой, неожиданной стороны. Исследованиях невероятных настолько, что уверен — многие сочтут их безумием. Есть два интересных и важных термина — «искусственный интеллект» (ИИ) и «сильный искусственный интеллект» (СИИ). В английской традиции Artificial intelligence (AI) и Artificial general intelligence (AGI). Первый подразумевает любую деятельность компьютера, имитирующую человеческий интеллект, второй — только такую, которая претендует на что-то универсально общее, похожее на то, как мыслит человек. Точного определения СИИ нет. Лучшее, что есть — это знаменитый . «Человек взаимодействует с одним компьютером и одним человеком. На основании ответов на вопросы он должен определить, с кем он разговаривает: с человеком или компьютерной программой. Задача компьютерной программы — ввести человека в заблуждение, заставив сделать неверный выбор». Если человек признает, что не может отличить двух скрытых собеседников, то можно говорить о достижении компьютером уровня СИИ. Отметим очень тонкий и при этом очень важный момент. Простой ИИ может во много раз превзойти человека в какой-то области. Например, сильнее играть в шахматы, обыгрывать в Го или Starcraft. Но от этого он не становится сильным. В английском названии СИИ не случайно называется общим или универсальным. Суть этого названия в том, что СИИ должен уметь решать не одну конкретную задачу и даже не широкий набор задач, он должен быть человекоподобным. То есть обладать способностью, начав с нуля, вникнуть в любую область и начать ориентироваться в ней подобно тому, как это способен делать человек. И желательно не хуже человека. И тут мы приходим к понятию «смысл». В принципе, отличие человека от современных программ заключается в том, что программы и алгоритмы пока не способны уловить суть того, что происходит или о чем говорится. Они оперируют выученными шаблонами, не задаваясь вопросом о смысле. Даже великий и могучий является, по сути, огромным генератором правдоподобного бреда и даже близко не приближается к пониманию того, что он генерирует. Берусь утверждать, что для создания СИИ в первую очередь надо понять, что есть смысл. Но легко сказать. Вся современная философия построена вокруг различных попыток это сделать. Но результата, который можно было бы описать формально и запрограммировать, пока нет. Как же формально описать смысл? Для начала надо договориться, о каком смысле пойдет речь. Слова коварны, каждый может дать свое определение смысла и быть совершенно прав внутри данного им определения. Двое с разными определениями могут спорить до хрипоты и никогда ни о чем не договорятся; собственно, философия — яркий тому пример. Нас будет интересовать то понимание смысла, что существует у людей интуитивно и то, которое ложится на суть теста Тьюринга. Тут надо пояснить. Еще Сократ обнаружил удивительную вещь. Люди знают язык, понимают его слова, тонко чувствуют, когда какое слово уместно употребить, но редко когда могут объяснить свое знание. То есть наш мозг знает много больше, чем мы можем объяснить. Сейчас такие знания принято называть имплицитными. Интересно, что когда человек пытается объяснить то, что знает его мозг, он не может получить непосредственный доступ к этим своим знаниям. Например, он не может их просто вспомнить. Знания есть, но они недоступны. Доступен только результат использования этих знаний. Поясню на примере. Прочитав шутку, вы смеетесь. Объявление: меняю бензопилу на протез. Но если вас спросить, что в шутке смешного, вы озадачитесь и скорее всего дадите объяснение, которое будет неверным. Если бы ваше объяснение было верным, то вы, зная секрет юмора, могли бы легко придумывать смешные шутки и стать знаменитым юмористом. Ваш мозг всегда знает, смешно или не смешно, но вы практически никогда не можете объяснить, почему. Более того, ваш мозг тонко чувствует разницу между просто смешным и юмором, а вы? Так вот, мы будем говорить о смысле в том понимании, какое стоит за этим словом, когда мы используем его в речи, не пытаясь дать ему четкого определения. Дело в том, что наивное определение, которое дается, пока явление еще не понято, будет обязательно построено на неких видимых признаках и в итоге опишет нам совсем другое. Платона попросили дать определение человека. Он сказал: двуногое без перьев. Диоген принес ощипанного петуха и сказал: вот человек. Сказанное не значит, что смысл непостижим и не может быть выражен словами. Просто сложные явления не стоит недооценивать. Кстати, для извлечения неочевидных скрытых знаний Сократ придумал удивительный метод, который так и называется: . Метод актуален сегодня, как был и во все времена, очень рекомендую. Итак, приступим к «извлечению» природы смысла. Чтобы описывать окружающий мир, наш мозг в результате эволюции приобрел возможность формировать внутренние понятия. Такое представление сегодня достаточно распространено, на нем основана , согласимся с этим и мы. Формирование внутренних понятий происходит под воздействием опыта, который человек получает из окружающего мира. Хотелось бы сказать, что явления, окружающие нас, приводят к отражению их в понятия. Но беда в том, что в самом мире явлений нет, явление — это тоже одно из наших понятий. Скажем так: наличие в окружающем мире определенной структуры приводит к формированию понятий, способных адекватно эту структуру описать. В какой-то момент эволюции у человека появился язык. Внутренним понятиям были сопоставлены слова. Устные слова — это просто звуки, они не несут смысла сами по себе. Но будучи связанными с понятиями, передают их значения. То есть за содержание отвечает внутреннее понятие, а слово — это внешняя форма понятия. При этом надо учитывать, что далеко не всем внутренним понятиям соответствуют какие-либо слова. Язык развивался и в нем появлялись новые слова. Кроме непосредственно обозначения того, что видно или слышно, в языке стали появляться слова, обозначающие некие сложные, порой абстрактные явления. Люди открывали для себя эти явления и через язык давали им названия. Например, так появились слова: «понятие», «логика», «определение» и тому подобные. Для появления внутренних понятий, в принципе, язык не нужен. Они сформируются и без него. Своя система понятий сформируется и у Маугли. Но с момента своего появления язык стал влиять на то, какая именно система внутренних понятий формируется у людей. Образование понятий напоминает рост виноградных лоз. Для лозы направляющая служит опорой и задает направление ее роста. Сколько есть направляющих, столько лоз их обовьет. Для формирования внутренних понятий слова языка во многом служат такими направляющими. Изобретенные когда-то слова, обозначающие некие абстракции, и сегодня позволяют сформироваться у нас понятиям, которые не возникли бы сами по себе без участия языка. И вот мы подходим к самому интересному. Хорошо, внутри у нас есть набор понятий. За каждым понятием стоит некое содержание. Но как мозг это содержание описывает? Что это за содержание? Каков его механизм? Собственно, это и есть те самые главные вопросы, от ответа на которые все зависит. Ведь, по сути, мы говорим о том, что за каждым понятием стоит некий смысл. И этот смысл и определяет содержание понятия. То есть, когда мы говорим, что мозг умеет, наблюдая за миром, формировать понятия, мы говорим о том, что мозг умеет формировать описания смыслов. Заданные вопросы очень коварны. Дело в том, что ответы на них слишком очевидны. Предположим, вы бог и вам надо «запрограммировать» мозг. Как вы в своей программе зададите понятия? Скорее всего так же, как естественным образом это сегодня пытаются сделать многие создатели ИИ. Попробуем воспроизвести их рассуждения. Чтобы сформировать набор понятий, описывающих мир, надо поделить этот мир на области, которые можно назвать, например, классами, кластерами или как-либо еще в зависимости от вкуса. Чтобы было проще, стоит, посмотрев на число слов в языке, ограничить себя, например, набором из десятка тысяч понятий. Каждое из понятий должно объединять похожие друг на друга явления. Но из-за бушующего многообразия явлений (в море каждая волна уникальна) эти классы нельзя задать простым перечислением. Надо придумать что-то более универсальное. Вполне логично дальше для каждой группы явлений, относящихся к одному понятию, создать свой прототип. То есть вычислить образ идеального явления. Чтобы описать портреты явлений, нам понадобятся признаки. На роль признаков подходят другие «более мелкие» явления. Удава можно измерить в попугаях. Признаки, конечно, сами потребуют описаний, но тут мы выкрутимся, сделав многоуровневую конструкцию и пойдем от простого к более сложному. Если мы запишем признаки в вектор, то получим очень удобное . Например, это может быть вектор, в котором каждое число указывает на степень выраженности соответствующего признака в явлении. Можно придумать и что-то посложнее, не суть. Дальше нам понадобится обвести прототипы границами. Что внутри границ — относится к понятию, что выходит — нет. Для этого придется придумать некую метрику, которая позволит, взяв одно описание, сравнить его с другим. Если мы имеем дело с векторами, то таких метрик сотни и можно выбирать любую по вкусу. Конечно, если подходить серьезнее, то имея учителя, который скажет, какое явление к какому понятию относится, мы сможем не только рассчитать центр класса и назвать его прототипом, но и вычислить характер распределения. Это может сильно помочь на практике. Средний вес килограммовой гири — один килограмм. Средний вес курицы 3 килограмма. Нечто весом кило сто, исходя из распределений, скорее будет курицей, чем гирей. Хотите знать подробнее, смотрите методы классификации и кластеризации, . Рано или поздно обнаружится, что все явления многогранны, тогда можно будет усложнить схему. Например, искать ключевые признаки, определяющие явление, либо пытаться для каждого явления задать набор его возможных проявлений и очертить границы вокруг них. Собственно, вот вам краткий курс нейронных сетей. Сухой остаток: понятия можно задать через перечисление их признаков, тем самым разбив мир на области. Затем можно совершенствовать описания, уточняя прототипы и границы вокруг них. Разделяй и властвуй. Так действительно можно сделать. На этом основаны методы математической статистики, в этом основная идея машинного обучения, на этом же фундаменте построен колосс нейронных сетей. Так в чем подвох? А в том, что когда заходит речь о словах языка и, как следствие, о стоящих за ними понятиях, то в первую очередь всплывает именно такая модель. И полагается вполне очевидным, что, видимо, мозг делает точно так же. Что, как и в искусственной нейронной сети, в мозгу есть , бодро реагирующие на ее появление и хранящие на своих весах ее портрет. Другими словами, кажется вполне очевидным, что у каждого понятия есть его определение. А значит, потрудившись, можно дать определения всем понятиям и тем самым понять скрытые знания человека. И тут мы возвращаемся к смыслу. С одной стороны, за каждым понятием стоит его смысл. С другой, мы только что рассудили, что понятию можно дать определение. Выходит, что определение и есть смысл? Очевидно, что нет. Но в чем тогда разница? И тут приходит спасительная мысль: даже если определение пока не соответствует смыслу, то можно постараться определение уточнить, приблизив к оному. Напрашивается вывод, что определение понятия — это его «недоделанный» смысл, который при желании можно «доделать». И тогда смысл хочется истолковать как некое «идеальное» определение. Отсюда возникает вера, что усложняя описания понятий, создавая онтологии, описывая связи между понятиями, мы рано или поздно сможем постичь смысл и создать СИИ. В популярном буддистском коане говорится: «Рыжая корова проходит мимо окна. Голова, рога и четыре ноги прошли. Почему не может пройти хвост?». В математике беда почти всегда приходит с одной и той же стороны. И имя этой стороны — . Имея дело с тепличными примерами, не нарадуешься красоте определений. Но стоит только «выйти в поле», и все идет прахом. Любое реальное явление начинает давать такое разнообразие проявлений, что никакие вычислительные мощности и датасеты не могут за этим разнообразием угнаться. Все время кажется, что осталось еще совсем немного дообучить модель и все будет хорошо. Мы слышим: автопилот для автомобилей уже почти готов, осталось пару месяцев. На моей памяти эти пару месяцев слышатся последние года три. Правда, сейчас говорят: три месяца и точно. Проклятие размерности — оно такое. К сожалению, корову не определяет ни ее цвет, ни ее рога и ни ее копыта, и «хвосту» всех признаков никогда не пройти мимо. В этом и есть разница между ИИ и СИИ. Простой ИИ строится на использовании сущностей, заданных определениями. Отсюда классы, кластеры, тезаурусы, онтологии, нейроны бабушки и тому подобное. СИИ, который может пройти тест Тьюринга — это, в первую очередь, интеллект, оперирующий смыслом. Так что же такое смысл и чем он отличается от определения? Попробую объяснить. Предположим, есть нечто, на что мы смотрим. Допустим, мы не узнаем предмет перед нами. Тогда мы можем изменить точку зрения и посмотреть на него с другой стороны. Если изучаемый предмет в принципе нам знаком, то должна найтись такая точка зрения, с которой мы его, наконец, узнаем. На этом можно было бы и закончить, предмет опознан, что еще? Но важно (и об этом часто забывают), что кроме того, что нам удалось понять, что перед нами, мы еще узнали и точку зрения, глядя с которой, у нас все и сложилось. Почему это важно? Дело в том, что любое понятие может быть точкой зрения. За всяким понятием стоит явление, которое меняет наше восприятие мира. Одно и то же мы начинаем видеть по-разному в зависимости от того, через призму какого явления мы смотрим. «Ицик, сколько будет дважды два? А мы таки покупаем или продаем?». Так вот, если, глядя через призму явления, мы увидим правдоподобную картину, то это будет означать, что скорее всего в этот момент присутствует и само явление. «Дважды два — пять» — продаем, «три» — покупаем. То есть самого явления может быть вообще не видно, но по его влиянию на картину мира мы можем понять, что оно есть. Это как тот Чеширский кот, когда сначала появляется его улыбка, а вслед за ней сам кот. Уловили идею? Вы видите комнату и в ней разбитую вазу. Сначала это просто «разбитая ваза». Но если посмотреть на это в предположении, что в комнате есть кот, то появляется картина «кот задел вазу и она, упав, разбилась», вот она, улыбка. Эта картина оказывается вполне правдоподобной. В этот момент вслед за своей улыбкой появляется и он сам. То есть вы узнали кота, вообще не видя ни его, ни каких-либо его непосредственных признаков. Настоящая «магия» заключается в том, что для каждого явления, наблюдая за ним, можно составить правила, по которым из исходного описания получается его трактовка. То есть любое явление может быть контекстом, в котором исходное описание заменяется его трактовкой в этом контексте. Что это дает? Это позволяет проделать мысленный эксперимент. Имея сформированный контекст, для любой входной информации можно, используя вычисленные правила, получить трактовку в этом контексте. Это как, имея волшебную лампу Аладдина, посмотреть, что будет, если примерить на людей другие роли. Получится ли что-то разумное или же выйдет полный бред. Важно, что осмысленная трактовка появляется в контексте только тогда, когда есть существенная вероятность, что присутствует соответствующее явление. Отсюда возникает алгоритм. Возьмем все слова языка, сформируем вокруг них контексты, то есть вычислим правила трактовок. Теперь, когда будет поступать новая информация, будем смотреть, в каких контекстах трактовка оказалась наиболее достоверной. В этом можно увидеть многое от . В нем, используя накопленные данные, для каждого интересующего нас события строится условная плотность распределения. То есть строится картина того, как будет выглядеть распределение при условии, что данное событие уже реализовалось. Затем новые данные примеряются к этой плотности для того, чтобы оценить, насколько достоверно они выглядят на фоне этого распределения. Проделав это для всех возможных событий, можно судить о том, в каком предположении все выглядит наиболее достоверно, и из этого сделать заключение о присутствии соответствующего события. Но как в случае контекстов оценить достоверность трактовки? Очень просто — трактовка должна выглядеть, как что-то нам ранее знакомое. Это значит, что надо иметь память того, что мы знаем, и сравнивать трактовку с памятью. Увидели что-то знакомое, значит, контекст подходит. Причем во всех контекстах память должна быть одна и та же. Тут напрашивается сравнение со . В них один и тот же набор ядер свертки (одна и та же память) примеряется к разным частям изображения. Там, где есть совпадение, мы говорим об обнаружении соответствующего образа. При этом сами позиции, в которых осуществляется свертка, по сути, выступают в роли контекстов. Мы примеряем известные нам картинки в предположении, что эта картинка сдвинута к соответствующей позиции. Поясню, ядро свертки — это маленькая картинка. Она примеряется к какому-то месту большой картины. Это равносильно тому, что мы взяли пустую большую картину, в центре которой разместили маленькую картинку. Сдвинули маленькую картинку к нужному месту, а затем сравнили две больших картины. Но у наших контекстов есть принципиальные отличия и от байесовского подхода, и от сверточных сетей. Самое главное в том, что там к неизменной входной информации примеряется некое «искажение» памяти. Вот «искаженное» по отношению к исходному условное распределение. Вот ядра свертки, перемещенные так, чтобы оказаться в нужном месте изображения. У нас же память всегда остается неизменной, а «искажается» входная информация. Вместо исходного описания в каждом контексте появляется его трактовка. Если гора не идет к Магомету, то Магомет идет к горе. Кроме того, в сверточных сетях важно то, «что увидели». В байесовском подходе — то, «где увидели». У нас же — и «что увидели», и «где». Но, пожалуй, самое главное отличие — это возможность автоматически построить пространство контекстов. В сверточных сетях правила свертки воспринимаются как нечто естественное, следующее из законов геометрии, и вопрос об их формировании не ставится. Зачем, если они, правила, и так понятны? Мы же говорим, что для любой информации можно сформировать пространство контекстов, обучив контексты соответствующим правилам трактовки. Кстати, мы показали, как в зрительной истории контексты, соответствующие правилам свертки относительно несложно получаются при самообучении. В результате получается, что полное задание конкретного понятия требует трех вещей. Нужны: имя понятия. Слово языка или внутреннее кодирование имени понятия. правила трактовки. Правила преобразования, индивидуальные для каждого контекста. память. Накопленный ранее опыт, один и тот же для всех контекстов. И работает эта триада не по отдельности, для каждого понятия, а только в пространстве всех понятий, где происходит сравнение результатов между собой. Теперь возвращаемся к смыслу. Смысл понятия — это и есть описывающий его контекст, состоящий из правил трактовки и памяти. Смысл информации — это тот контекст, в котором трактовка выглядит достоверно, и сама полученная трактовка. И, заметьте, что смысл не сводится к определению. Он имеет совсем другую природу, в которой нет привычного прототипа и границ вокруг него. Поясню все на моем любимом примере. Во время второй мировой войны немцы использовали шифровальную машину под названием «». Сообщение на входе перекодировалось так, что одни буквы заменялись другими по достаточно сложным правилам. Кодирование происходило с помощью ключа. Если на принимающей стороне ключ был известен, то можно было через обратное преобразование восстановить исходное сообщение. Шифровальная машина «Энигма» Примерно в декабре 1932 года , польский математик и криптоаналитик, смог разработать алгоритмы, позволяющие потенциально взломать код «Энигмы». В это же время французской разведке удалось получить ключи, реально используемые немцами, и передать полякам. Анализируя перехваченные сообщения, Реевскому удалось восстановить внутреннюю схему «Энигмы». Для расшифровки немецких сообщений поляки построили шесть машин, «бомб», которые позволяли за разумное время перебрать 100 000 возможных кодов и найти среди них верный. В 1938 году немцы усложнили конструкцию «Энигмы», в результате чего расшифровка ее сообщений стала в десять раз сложнее. За пять недель до вторжения Германии в Польшу в 1939 году Реевский и его коллеги передали свои результаты французской и британской разведке. Это позволило англичанам построить в Блетчли-парк батарею из «бомб», которая успешно взламывала немецкие коды на протяжении всей войны. Определенную роль в этом сыграл тот самый , что придумал приведенный в начале тест. Немецкие шифровальщики могли ежедневно менять коды, поэтому главной задачей англичан было найти актуальный код, после чего все остальное становилось делом техники. Для этого приходилось брать сообщение и перебирать с помощью «бомб» миллион возможных вариантов. То есть смотреть на сообщение в миллионе возможных контекстов, получая миллион его потенциально возможных трактовок. Если код был неверен, то на выходе получался бессмысленный набор знаков, но как только обнаруживался правильный код, сообщение приобретало смысл. Главный вопрос был в том, как без участия человека понять, что сообщение получилось осмысленным? Оказалось, что каждая ежедневная немецкая метеосводка заканчивалась одной и той же подписью – «хайль Гитлер». Зная это, англичане брали утреннюю метеосводку и перебирали коды до тех пор, пока эта подпись не появлялась в конце сообщения. Можно было бы обойтись и без известной подписи, а ждать, чтобы слова в сообщении стали правильными, то есть соответствующими немецкому языку. Это и есть сравнение трактовки с памятью для определения ее достоверности. И самое главное — при расшифровке прогноза погоды англичан не интересовал сам прогноз погоды. Был важен контекст, то есть код, в котором получалась удачная расшифровка. Напомню, что в контекстно-смысловом подходе удачная трактовка – это только часть расшифрованной информации, другая часть – это контекст, в котором эта трактовка возникла. Замечу, что разбираясь с контекстным подходом, удобно представлять себе «Энигму» и ее коды. Если понять правильные сопоставления, многое становится простым и понятным. Для полноты картины отмечу, что кора человеческого мозга делится на зоны, которые в свою очередь состоят из . Каждая из миниколонок — это порядка сотни нейронов, расположенных вертикально, с плотными связями между собой и менее плотными по сторонам. У меня есть статьи, где показывается, что каждая из миниколонок является реализацией отдельного контекстного модуля и что память зоны коры продублирована в каждой из ее миниколонок. При этом сами зоны коры являются пространствами контекстов. Таким образом, анализируя информацию, человек одновременно рассматривает ее во множестве различных контекстов, выбирая из них наиболее подходящие. Я полагаю, что мышление человека основывается именно на контекстно-смысловых принципах. Конечно, это только начало разговора о контекстах. Далее должен следовать разговор о форме кодирования понятий, о методах хранения памяти, о механизмах поиска закономерностей, о рекуррентной модели, реализующей формальные грамматики, о пространственной организации контекстов, о реализации обучения с подкреплением, о формировании удачных описаний и многое другое. Подробнее об этом есть в . Все, что было сказано, было странно, но не безумно. А где же обещанное безумие? Начнем. Разрабатывая контекстно-смысловую модель, мы постоянно задавались вопросом: неужели никто раньше до этого не додумался? В конце концов, а как же философы? Великие древние, которые рассуждали об устройстве мира и разума? И постепенно до нас стало доходить. Как вы думаете, кто такой Диоген? Почему он жил в бочке? Почему ел прямо на рынке? Почему с фонарем искал честного человека? Почему его взбесило, когда горожанин нацепил на себя шкуру льва? Пазл стал складываться. Мы с удивлением обнаружили, что в древних текстах и преданиях скрыто огромное количество устойчивых, согласующихся между собой и непротиворечивых аллегорий, непосредственно отсылающих к философии смысла. К той философии, что говорит ровно о том, над чем работаем мы. В итоге параллельно с созданием СИИ наша команда несколько лет работала над разгадками древних аллегорий. И выяснилось, что действительно, ничто не ново под луной. И шумерские мифы, и египетская книга мертвых, и аккадский Гильгамеш, и греческие легенды, и буддийское учение, и Ветхий, и Новый Завет, и Талмуд, и Коран, и «Сказки тысяча и одной ночи», и много что еще оказались аллегорически зашифрованными рассказами о философии смысла. А еще обнаружилось, что причины шифрования философии смысла в священные тексты и превращение этих текстов в религии было не забавной шуткой авторов и не капризом истории, а страшной драматической необходимостью. Все наработки мы постепенно начали выкладывать на сайт нашего проекта . Понять основные посылы можно из или посмотрев короткое видео, где, кстати, рассказывается, почему не стоит бояться конца света. Ну и в развитие темы о смысле и определении я хотел бы предложить вам рассказ о том, как на это смотрели наши предки и какие подсказки они нам оставили. Я понимаю, что это будет достаточно неожиданно, и уверен, многие сочтут за сумасшествие, но я специально сделал это видео в форме провокации, не пробуя что-то доказать, а пытаясь возбудить любопытство и вызвать желание разобраться глубже. Алексей Редозубов Теги: Добавить метки Хабы: Укажите причину минуса, чтобы автор поработал над ошибками Отправить анонимно Пометьте публикацию своими метками Метки лучше разделять запятой. Например: программирование, алгоритмы Сохранить Баннер исчез, но на прощание оставил коллекцию по работе с продуктами от Microsoft Читают сейчас 17,5k 5,3k 11,2k 14,4k 2,5k 1124k Мегапост Редакторский дайджест Присылаем лучшие статьи раз в месяц Скоро на этот адрес придет письмо. Подтвердите подписку, если всё в силе. +9 34 3,7k Поделиться Скопировать ссылку Нарушение Опишите суть нарушения Отправить Пользователь Платежная система Похожие публикации 6 апреля 2021 в 13:14 11 2,6k 30 6 апреля 2021 в 11:28 47 4,7k 19 5 апреля 2021 в 15:20 8 7k 45 AdBlock похитил этот баннер, но баннеры не зубы — отрастут Минуточку внимания Комментарии 83 вчера в 16:04 +5 Попытка сделать нечто работающее исходя из философии? Проект обречен на провал. вчера в 16:14 +2 Более того, главный вывод: «Статья написана по результатам прочтения научпопа. Авторы сами разрабатывать нейросети не умеют. Запускать — может быть.» вчера в 16:24 +1 Несколько не так. Мы уже сделали много работающего и после этого стали понимать что-то в философии. сегодня в 03:19 0 То есть вы достигли результата не в разработке ИИ, а в том, что продвинулись немного в философии? Для начала, тест Тьюринга совсем не самое лучшее, что может быть. Условия теста никак не проверялись на соответствие человеку. Взять 100 человек разного возраста и состояния здоровья, и дать им пообщаться с группой экспериментаторов по чату. Как много «ИИ» найдет группа экспериментаторов, если будет считать что им нужно отличить человека от ИИ? Если найдет хоть одного, значит данный тест Тьюринга ни о чем. Такой эксперимент кто-то проводил, чтобы убедиться что тест рабочий? Я не слышал. Во-вторых, условие — поговорить с человеком, и почти весь ИИ который участвует в таких тестах заточен не на развитие именно интеллекта, а на обман человека в разговоре при помощи базы данных и так далее. При этом ИИ не выходит за рамки разговора. Человек, который пройдет тест Тьюринга может пройти другие тесты, возможно ему нужно будет немного подучиться, но это он сможет сделать самостоятельно. Он может выполнять и другие задачи. А ИИ, которого обучили чатиться — сможет только чатиться. вчера в 22:32 0 Из философии это «означаемое» и «означающее» — дихотомия языкового знака, но их автор не знает вчера в 16:31 0 “сильный искусственный интеллект” (СИИ). В английской традиции… Artificial general intelligence (AGI). Перевод не соответствует. Вместо «сильный» аккуратнее «общий»/«обобщенный». вчера в 16:32 0 Через абзац об этом. вчера в 17:10 +2 "… великий и могучий GPT3 является, по сути, огромным генератором правдоподобного бреда и даже близко не приближается к пониманию того, что он генерирует". Только если представить ее не выучившим урок учеником, стоящим возле школьной доски. Это из- за того, что понятие «понимание» у Вас очень уж усложнено антропоцентризмом. вчера в 17:21 0 Просто недавно на семинаре сообщества AGI была озвучена эта формулировка и все с ней согласились. Она понравилась и мне, отчего я ее позаимствовал. Но у вас может быть свое мнение. вчера в 18:06 0 Для того, чтобы связать разбитую вазу с котом не обязательно знать язык и быть человеком. А в Вашей статье это чуть не признак «понимания». Существуют на данный момент нейросети, способные по видеоряду пояснять, что происходит на экране. Примитивным пока образом, но дайте им ресурсов. Вот я о чем. вчера в 18:15 0 «Дайте им ресурсов» — это и есть шаги по пути, ведущему в комбинаторный взрыв. вчера в 19:40 0 Напомните, когда человек начал проигрывать компьютеру в шахматы? вчера в 21:13 +3 Понимание происходящего вне шахматной доски у компьютера от этого не появилось. вчера в 21:34 +1 Тут, ниже очень хорошо написано, что понимание это системный процесс. Человек и бот или китайская комната. Вы никогда достоверно не узнаете, что у вашего собеседника в голове. Есть только Ваш субъективный вывод, мысли. Я не согласен с трактовкой автора понятия «понимание». И как правильно он заметил это мое личное мнение. Уже зарекся дискутировать на эту тему. Единственное, что меня заставило вклиниться в беседу так это знак равенства, поставленный автором между GPT3 и китайской комнатой(о понимании), что далеко не так. вчера в 22:19 0 кое-что "понимает вне доски". вчера в 21:21 +1 Если вы намекаете на обуздание комбинаторики методами альфа-бета отсечения, Монте-Карло и deep learning, то тут речь не об этом. Пространство решений игры — ничто по сравнению комбинаторикой реального мира. В вашем примере правила игры, как и размерность игрового мира, ограничены, известны заранее и не меняются, пусть даже модель их не знает (AlphaZero). Поэтому в статье и отмечено, что сравнительно легко написать специализированный ИИ, который уделает человека на своем поле. Но все становится плохо, как только приходится иметь дело с открытым миром. вчера в 21:39 0 Странно, что инфузория туфелька до сих пор не вымерла в ОТКРЫТОМ мире. вчера в 21:47 0 Зря вы иронизируете. Вашей инфузории, на минуточку, потребовались миллиарды лет эволюции, сложнейшая биохимия и сама жизнь в придачу, чтобы выжить в открытом мире. И все это чтобы «бесцельно» плавать в лужице. А так да, все кажется простым, пока отбрасываешь «незначительные детали». То же и в ML. А потом оказывается, что велосипеды могут ездить боком по шоссе со скоростью 100 миль в час. вчера в 21:54 0 А теперь масштабируйте время теоретических и практических работ в области генетических алгоритмов и нейросетей с временем эволюции инфузории вчера в 20:58 +1 Скорее всего у гпт-3 вся проблема в памяти и обучении, она запоминает все что показывают и делит на объекты, представьте ребенку или любому пустому разуму показывают набор картинок — это почти сферический ребенок в ваккуме, не считая картинок. Или ГО, или ионтесуме. Конечно сеть не умеет ничего другого, потому что ее не учили. Ей нужен огромный объем памяти и возможность тусить в окружающем мире, например бостон динамикс, ну и облака огромной мощности для обработки инфы, целые ангары видюх от майнеров тоже подойдут. Или вместо реального мира его симуляции на огромной скорости, но это будет разум во снах, ему надо будет действовать в реальном мире иначе он погрязнет в этих снах. Потребуются время и мощности довольно большие и в тоже время очень малые, чтобы двигать не только персонажами в игре, а процессами в мире который ты видишь через камеры и щупаешь манипуляторами вчера в 21:07 0 Статья как раз о том, что так не сделать. вчера в 21:25 0 Вот вот, одна и таже сеть играет в разные игра, оперирует со словами слаборазвитый человек. Ее с рождения держат в темной коробке показывая мельком куски реальности. Хз откуда но она что-то делает а значит у нее есть мотивация. Пифагор жил в бочке потому что, у него были руки и ноги и бочка, и глаза и он рос с младенчества длительное время, его воспитали и научили. А разные инстансы нейросети тоже в итоге разные Написал максимально просто. вчера в 21:26 +1 В бочке жил Диоген ) вчера в 23:06 0 кто знает может и пифагор временами жил в бочке. На самом деле я просто перепутал, это смешно) сегодня в 04:53 0 в первом предложении я наделал кучу ошибок, правильно — Вот вот, одна и та же сеть играет в разные игры, оперирует со словами как слаборазвитый человек… вчера в 17:14 0 Очень рекомендую почитать технокосм Лазаревича и вообще нф литературу, вы удивитесь сколько разных потенциально рабочих идей там описано. сегодня в 08:42 0 У Лазаревича нет идей, направленных на создание ИИ. Если вы про переводчика и Примечание переводчика, то там не поясняется связь между текстом и семантикой текста, ключевая для работы этой системы. вчера в 17:15 +1 «Лучшее, что есть — тест Тьюринга»… Мда. Тест Т., — это игра в имитацию, к сожалению. А в том, что определения нет (пока нет) — согласен. Но как насчет вот такого: Интеллект Объекта — это набор способностей Объекта, которые используются: (1) При идентификации, формализации и запоминании законов состояния и/или поведения: (1.1) Окружающей среды Объекта, и (1.2) Внутренней среды Объекта на основе законов эволюции. (2) При опережающем моделировании состояний и/или вариантов реального поведения Объекта: (2.1) По отношению к Окружающей среде, и (2.2) По отношению ко Внутренней среде на основе законов эволюции. (3) При создании описания состояния и/или реального поведения Объекта, адаптированного: (3.1) По отношению к Окружающей среде, и (3.2) По отношению ко Внутренней среде при условии максимизации отношения «(Реальное поведение Объекта)/(Затраты на реальное поведение Объекта)» с целью сохранения (существования, дления, бытия, жизни) Объекта по отношению к Окружающей и Внутренней средам Объекта. вчера в 17:22 0 «Но как насчет вот такого?». Сама статья ответ на ваш вопрос. вчера в 17:45 0 А если все отдать на самотек? Вот писали алгоритмы, они работали так себе, а в итоге оказалось что надо сетки тренировать. Что если эмулировать некий мир с законами выживания, и надолго "запустить" туда нейросетки? вчера в 18:21 0 1 нейросети начисто сливают алгоритмам по "КПД" — на одинаковый результат алгоритм тратит меньше ресурсов чем нейросеть. Проблема в том что для некоторых задач алгоритмов банально не придумали, тут то и вылезли нейросети которые можно обучить. 2 современные нейросети на многие порядки примитивнее даже куриного мозга, а большинство примитивнее нервной системы какого нибудь червяка. И это не потому что достаточно или нет желания, а потому что нет достаточно производительных компьютеров. На осуществление вашего же предложения скорее всего не хватит производительности всех компьютеров в мире вместе взятых. вчера в 18:24 0 Наоборот, контекстная модель во многом получается менее прожорливой чем нейросети. вчера в 18:33 0 И тем не менее, оно заманчивое, правда? Что касается мощности, то когда то биткоин безумие кончится, и будет море дешёвых видеокарт вчера в 23:17 0 Оффтоп: есть работы по аппроксимации физической симуляции нейронными сетями с целью увеличения производительности. вчера в 23:43 0 Сложно сказать что это действительно так. На самом деле современные нейросети делают много вещей которые червяки не умеют, например распознавание места на земле по фотографии, или замена лица на видео, и еще много чего. С другой стороны, нейросеть не умеет как червяк ползать под земелей или нести яйца как курица. Летать как курица и в чем то лучше ( на дронах ) он уже умеет, и на компютерных моделях учится ходить, так что в итоге часто похоже на походку реальных животных или человека. По идее при достаточном количестве нейронов можно управлять биологическим телом с кучей нервов. Главное найти способ совместить кремнивые мозги и нервы вчера в 23:45 0 Сделай нас единым! вчера в 23:53 0 Мммм… А управлять синтезом белков и прочей выполняющейся в ядре живой клетки несущественной ерундой нейросеть может, для начала?.. Митоз там всякый… :) сегодня в 00:46 0 да есть принтеры синтетических днк, которые сначала моделируются на компьютере, а потом печатаются на принтере, тот же проект организма с минимальным геномом. Но опять же нейросети надо учить понимать как работает днк, и она уже находит новые закономерности, и новые варианты белков по заданным параметрам. Все упирается в обучение сегодня в 00:48 0 Например если люди не будут знать о радиации, то и нейросеть тоже не будет знать пока не станет настолько умной чтобы найти радиацию самой. вчера в 18:36 0 Объявление: меняю бензопилу на протез. Шутка понимается в результате нескольких шагов: 1. Картинка обмена чего-то (бензопилы) на что-то. 2. Предполагаемая ситуация — что-то является объектом с примерно равноценным бензопиле функционалом (например, надувная лодка или молоток — т.е. то, что может использоваться в работе/быту/на отдыхе). В любом случае предполагается, что предмет обмена обладает примерно такой же универсальностью, как и бензопила. 3. Нестыковка: протез — не тот объект, который является в достаточной мере универсальным. Включается анализ. 4. Возникает новая картинка: Человек без ноги протягивает бензопилу и хочет получить взамен протез. 5. Возникает осознание причины данной ситуации — человек отпилил себе ногу и теперь меняет уже ненужный ему объект на объект, ранее совершенно не нужный, но теперь ставший нужным. 6. Противоречие между ожидаемой ситуацией (обмен на равноценно «полезный в быту» объект) и фактической (обмен «уже ненужного» объекта на «ставший нужным» протез) вызывает улыбку. Обычно описанные выше процессы протекают в течение долей секунды, поэтому нетренированный человек их не осознает. Собственно, юмор очень часто строится на таком противоречии между ожидаемой ситуацией и фактической, например: — Продам проигрыватеь. — Срочно куплю выигрыватель! вчера в 18:44 0 Я именно об этом. Вы рассудили вполне логично. И правильно подметили, что юмор часто содержит противоречие. Из этого вы сделали вывод, что противоречие и есть причина смешного. Но это не так. Просто противоречие не смешит. Природа юмора глубже. Когда-то я написал об этом книгу . Там есть разгадка. вчера в 22:08 0 Не противоречие как таковое, а несовпадение ожидаемого с наблюдаемым. Например, если в темной комнате вдруг раздался какой-то пугающий звук, как будто от большого животного, а потом оказалось, что это был маленький котенок. Разумеется, подобные нестыковки — лишь один из методов создания юмористического эффекта. По-моему, существуют достаточно подробные перечисления этих методов. Но читать их скучно ))) Я же лишь хотел указать на то, что нетренированный человек, не осознающий процессы в своем сознании, зачастую неспособен отследить всю цепочку событий, приведших его к тому или иному состоянию. сегодня в 00:38 0 «один из методов создания юмористического эффекта». Дело в том, что нельзя подменять суть внешним проявлением. Попытка создать юмор по «методу» никогда не дает результата. сегодня в 01:21 0 Смешно это не когда нестыковки, а когда кому-нибудь другому плохо, или этот кто-то другой попадает в нелепую ситуацию. Большой звук от маленького котенка не смешно, а если кто-то повел себя глупо в связи с этим звуком, то будет смешно. Причем, привести к тому, что кому-то плохо должны были действия самого персонажа, если кому-то просто плохо, а он в этом не виноват, то вместо смеха будет сопереживание. сегодня в 01:25 0 Ну просто испуг даже внутренний, от тени котенка, переживаешь потом как глупость с облегчением, отсюда и смех. Кстати смех от протеза и бензопилы именно в том, что обдумывая объявление ты понимаешь что была страшная угроза, она воплотилась но больше ее не стоит бояться( пилу меняют ) , становится понятно причем тут протез, и самое главное вся эта история просто так, она не является информацией об угрозе, и ее не сложно обработать. Ты чувствуешь угрозу и она сразу проходит. Не обязательно юмор именно такой, он многогранен. Есть тот который понимаю люди кошки и собаки. Шимпанзе слоны и дельфины. И тот который понимают только люди или только дельфины например сегодня в 01:35 0 Ну, умение посмеяться над собой не всем дано, как-бы там ни было, в вашем примере как-раз и есть объект которому было плохо во время испуга. Вы сможете привести пример юмора, чтоб было смешно и никому не было плохо? Плохо в общем смысле, не обязательно увечья: кто-то попал в нелепую ситуацию, повел себя глупо и т.д. сегодня в 08:51 0 Кстати смех от протеза и бензопилы именно в том, что обдумывая объявление ты понимаешь что была страшная угроза, она воплотилась но больше ее не стоит бояться( пилу меняют ) Склонен доверять где-то услышанному мнению, что смех часто вызван наслаждением собственной догадливостью. Пример: Девочка в поле нашла пулемёт И по деревне открыла пальбу. Что же девчонку никто не уймёт? В ужасе прячутся люди в избу. Пули везде настигают несчастных, Без перерыва строчит пулемёт. Люди погибли в муках ужасных, Больше в деревне никто не живёт. Не очень смешно, всё разжёвано. А если так: Девочка в поле нашла пулемёт, Больше в деревне никто не живёт. сегодня в 01:39 0 Вы на правильном пути, но все еще интереснее. У меня в книге (ссылка выше) есть подробный разбор и смешного, и юмора. Главное было не просто понять, когда смешно, а докопаться до причин почему в эти моменты смешно. Собственно, об этом и книга. сегодня в 03:26 0 Юмор строится не столько на противоречии, сколько на противоречивом тождестве. Суть в том, что тождество можно заметить на высоком уровне абстракции, когда какие-то два понятия, каждое из которых имеет пласт ассоциаций, внезапно оказываются схожими под углом, который ты раньше не замечал. Связывание этих двух понятий (и всех их ассоциаций) и вызывает реакцию смеха. При этом, если шутку повторять, в мозгу возникнут устойчивые ассоциативные соединения, через некоторое количество повторов, она перестанет вызывать смех, будет вызывать «утомление», поскольку триггерится большое ассоациативных связей, активируя множество аксонов… Обратная реакция — горе. У тебя есть куча ассоциаций с каким-то понятием. И тут это понятия пропадает, становится бессмысленным, ненужным. Разорвать все ассоциации и привычки мозг просто так не может, а появление чувства утраты и ненужности этого вызывает практически физическую боль. Память у нас чистится в основном за счет того, что ты ее не используешь, а на это нужно не только время, но и собственно не активировать эти ассоциации, чтобы они «атрофировались». Собственно поэтому мы смеемся над новыми шутками недолго, а плачем над старыми горестями гораздо дольше. сегодня в 03:43 0 Вы плохо представляете природу эмоций. Они часть механизма обучения с подкреплением. Их роль — оценка текущего качества ситуации. Но эта оценка строится, исходя из прогноза будущего. Смешное и юмор хорошо объяснимы, но если вы хотите их понять, то не обойтись без понимания механизма появления эмоций. вчера в 18:37 0 Проблемы не могут быть решены на том же уровне мышления, который создал их. Альберт Эйнштейн вчера в 18:47 0 Смысл слова в модели. Я вижу вазу, когда есть модель "я", модель "видеть", модель "вазы". Фотоны, отражаясь от вазы формируют в голове "Зазеркалье", такой же мир, как и снаружи, только упрощённый, свёрнутый, но с особенностями, например, возможностью пройтись вбок по ассоциациям, в глубь по подробностям моделей, рассмотреть прошлое модели, возможные будущие, скомбинировать несколько моделей. Без физического мира и наблюдения за ним, сложно получить такие модели. Например, программа "видит" объект в своём внутреннем информационном поле. Это не отражённый объект, программа вызвала его для каких-то промежуточных целей, найти, на что похож наблюдаемый объект или тот, который станет возможно наблюдаем в будущий момент. Целая ваза и разбитая ваза как-то связаны. Но мы не можем наперёд знать форму, количество и расположение осколков, поэтому наша модель схематична, неточна. Но когда мозг видит прыгающий футбольный мяч, я верю, что внутри мозга мяч тоже прыгает, синхронно с настоящим, мы ожидаем удара, отскока, ожидаем промах или попадание, достраиваем траекторию во время матча, по положению ног игроков. вчера в 22:38 0 Поразительная невидимость. На вход нейронной сети нужно что-то подавать. Но вот мы закрыли глаза, заткнули уши, отрезали себя насколько возможно от сенсорной информации и мы всё равно производим работу мозгом. Да и даже наблюдая мир, мы можем отрешиться от него и полностью погрузиться в то, что видим только мы, внутри себя. То есть, кроме тех моделей, которые мы наблюдаем, существуют и те модели, которые мы создаём и которыми пользуемся. Динамические модели. Мы видим внутренние модели, которые представляют собой не трёхмерные объекты, а четырехмерные, объекты с историей жизни, в динамике, мы можем «промотать» яблоко от семечка, до съеденого или сгнившего, до дерева, в которое прорастёт семечко или какой-то мебели, в которое превратиться это дерево. Динамическая модель перечисляет свои кадры так, как нам удобно, чтобы мы могли вовремя предсказать, что произойдёт в нашей комнате (или что нас интересует в данный момент), до того, как это произойдёт и произведёт какой-нибудь разрушительный эффект. Нас чаще всего интересует опасность, те явления в мире, которые могут нам навредит. Если мы видим что-то похожее на кошку или на утку, обычно, это не имитация кошки, это именно кошка. Именно поэтому мы часто ошибаемся, когда видим в темноте монстров, созданных одеждой на стуле или тень, брошенная деревом на стену. Поэтому мы находим лица и животных в различных узорах. Нас интересуют хищники, нам нужно найти их как можно быстрее. Если что-то быстро движется, нам нужно испугаться, потому что если мы ошибёмся, это может стоить нам жизни. Динамические модели действуют постоянно, пока мы мыслим. Если я вижу кошку, я должен понимать, что такое кошка, у меня должна быть модель кошки внутри меня. Могут ли кошки летать? Ну, если пнуть… Могут ли кошки быть большими? Некоторые могут быть довольно большими. Могут ли кошки быть на полу? Может ли кошка быть в квартире, в которую до этого принесли кошку? Могу ли я, увидев кошку и закрыв глаза, быть уверен, что кошка всё ещё в комнате или рядом? Если кто-то мяукнет за спиной, может ли это быть кошкой? Конечно, после того, как люди начали создавать различные вещи, становится труднее отличать кошку, от тех многих вещей, которые созданы быть какими-то признаками быть похожими на кошку: изображение кошки, видеозапись кошки, звукозапись кошки, игрушка в виде кошки, кошачьи ушки на голову, кошачий костюм и т.д. Мир был опасен для человека. Как отличить, можно ли ступать на ту или иную поверхность? Может, там яма, острые колья, хищник. Человек нашёл решение. Человек стал сооружать для себя более предсказуемый мир. Если ты не уверен в окружающем мире, создай себе простой, надёжный мир, с твёрдыми стенами, полом и потолком, в котором пол не провалится просто так, стены не упадут, ничего не упадёт на голову. Построй себе дороги, выгони хищников, выруби леса, отведи воду, контролируй её уровень. Маленький ребёнок изучает окружающий мир. В основном, в этом мире почти нет опасностей. Горит огонь, нужно узнать, что такое огонь, больше я туда не буду лезть. Нужно узнать, что такое электрический ток, больше в розетку пальцы не суём. Нужно узнать, что такое вода. Больше я под водой не могу пробыть, нужно всплывать. Нож, оказывается острый, больше я не хочу резать пальцы. Ножка стола, оказывается, сильно твёрдая и не сдвигается ударом ноги. А что такое прищемить пальцы закрывающейся дверью? Подобные вещи мы не стараемся повторить. Боль, участие в мире, изучение его свойств на практике — дают достаточно полное представление о мире. После нескольких повторений негативных опытов, мы сразу же вспоминаем боль и контекст, в котором боль появилась. Проигрывается динамическая запись, как я подхожу к двери, сую туда пальцы и дверь закрывается. Мы практически видим это воспоминание. Мы видим дверь, видим себя, видим пальцы, видим процесс закрытия и даже чувствуем подобие боли в итоге. вчера в 19:02 0 Жаркие споры разгораются на тему того, что называть искусственным интеллектом, и как определить, что он достаточно сильный. Как будто его потенциальные создатели боятся, что переусердствуют в своих трудах, и сделают лишнего, либо создадут ИИ раньше других, но этого никто не заметит. вчера в 19:40 0 Лучшее, что есть — это знаменитый Тест Тьюринга. Нет, тест Тьюринга, по правде, ужасен. Он позволяет найти , а не сознание вчера в 20:45 +2 Не стоит добавлять разговор о сознании. Это другая сущность. Китайская же комната — это некая нелепость. Серл сказал, что можно записать все варианты ответов в книгу и все поверили. Этого сделать нельзя, очень быстро число записей превысит число атомов во вселенной, а требуемое количество будет не достигнуто даже на видимые доли процента. вчера в 21:01 0 Да нет, вполне можно представить такие же инструкции обработки данных, как в вашей программе например. Правильный ответ на китайскую комнату — это то, что понимание возникает на уровне системы, а не на уровне человека. Если при активации информационных элементов системы, хранящих понятия, будут активироваться соответствующие нейроны человека, тогда и он будет понимать китайский язык. вчера в 21:08 0 Нет, не будет. У нас во вселенной нет столько нейронов. вчера в 21:42 0 Вы меня простите. В интернете опять кто-то неправ, и я вынужден ещё раз помахать своим дилетантизмом. Я ничего не знаю про интеллект, нейросети и китайский язык, но: 1. Википедия, к примеру, говорит, что «Интелле́кт — качество психики, состоящее из способности осознавать...». Лично мне кажется, что «качество» есть свойство чего-то другого. Такое же свойство, как, скажем, температура, скорость… Невозможно набрать ведёрко качества, горстку температуры или упаковку скорости. Также мне кажется, что создать температуру или скорость в отрыве от объекта тоже невозможно, но почему-то создавать качество психики (которое, вообще-то, само по себе есть свойство чего-то, если что :)) считается возможным, и, более того, выполнимым. Да, можно создать математические функции, оперирующие абстрактными свойствами, но какое это отношение будет иметь к реальному миру? В математике, как показывает практика, вообще возможно всё, что угодно, даже корень квадратный из отрицательного числа и бесконечность делить на ноль, наверное, тоже можно. Но ведь мы же вроде тут за «смысл» бьёмся? Какой же смысл в интеллекте без сознания?.. Качество свойства сущности в отрыве от самой сущности?.. 2. Потом Вы хотите, чтобы мы все поверили, что число атомов во вселенной меньше числа вариантов китайских иероглифов. Первая ссылка из поисковика дала мне 85 568 иероглифов в каком-то словаре. 85568 ^ 85568 мой комп посчитал секунд за 5 или 7, получилось очень длинное число, но оно в любом случае конечно. А вселенная, как нам говорят — бесконечна, и число звёзд в ней, говорят, — бесконечно (я, конечно, не проверял), и в каждой очень много атомов, и очень много между ними, так что я, пожалуй, не поверю: моя диванная логика говорит, что конечное число меньше бесконечного по определению. Математическому определению. 3. Ну и тест Тьюринга, прикопались все к нему, прям молятся все на него. Когда комп скажет: «Пошли вы нафик со своими вопросами, мне ребёнка кормить надо», или «Завтра экзамен, а в интернете опять кто-то неправ» — вот тогда и поговорим, наверно, об интеллекте, как мне кажется. А пока — ну функция от функции, ну и чо?.. Когда комп начнёт себе задачи ставить — вот попомните тогда Скайнет добрым словом :)) И да, всё вышеизложенное есть Моё Личное МегаДиванное УльтраДилетантистическое Мнение в отрыве от действительной академии наук. Пятница сегодня, всем добра. :) вчера в 22:26 0 В википедии висит достаточно "романтическое" определение интеллекта из психологии. В области разработчиков ИИ оперируют определением intelligence которое привел michael_v89 . вчера в 22:53 0 Да кто б спорил-то. Я не могу отделаться от мысли, что ИИшники не на тот слой абстракций нацелились. К примеру, давайте попросим информационную систему построить модель персонального компьютера (как части окружающей среды) на основе входящей информации. Про комп нам известно, грубо говоря, всё. Какую информацию будем кормить системе? — Точный атомарный состав компонентов? — Типономиналы компонентов? — Принципиальную схему? — Логическую схему узлов? — Эпюры и диаграммы напряжений на шинах? — Низкоуровневые инструкции, исполняемые процессором? — Байт-код какой-нибудь? — Инструкции высокоуровнего языка? — Набор установленных программ (включая ОС)? — Возложенные на этот экземпляр задачи? Для нас, людей, всё вышеперечисленное может иметь смысл в одних случаях, и не иметь в других; сам анализ задачи, на каком уровне абстракций мы рассматриваем этот комп — имеет для нас, людей, смысл: покупаем ли мы новый, поднимаем упавшую ОСь, чиним материнку или сдаём в металлолом. Более того, в большинстве случаев все перечисленные действия для нас, людей, есть способ достижения целей, отличных от этого экземпляра вычислительной техники: чаще всего заработок, бывает помощь или даже гламурные дела, профессиональный рост или убить время. Что из этого будет смыслом для ИИ? Ничего, просто тупое следование алгоритму. Пусть даже сложному алгоритму, с миллиардом параметров — человеку не осилить, а машине пофигу, что будет на выходе — она в любом случае не будет отличаться от арифмометра. Дррррынц/дзынь — результат. Зачем? Низачем, просто потому, что меня этого и создали. сегодня в 02:30 0 85568^62 = 6.357782e+305, а 85568^63 мой компьютер уже отказался считать ) Для сравнения — количество атомов в наблюдаемой Вселенной составляет по разным оценкам от 4⋅10^79 до 10^81 вчера в 23:21 0 Чем тот же GPT-3 не китайская комната? вчера в 23:46 0 Не хотелось бы повторяться, но большинство людей ближе к китайской комнате, чем gpt-3 сегодня в 00:45 +1 Во вселенной приблизительно 10 в 90 степени частиц, имеющих массу. В русском языке порядка трех миллионов словоформ. Предложение из шестнадцати слов может иметь порядка 10 в 103 степени вариантов. вчера в 20:12 +2 Точного определения СИИ нет. Интеллект — это способность информационной системы строить модель окружающей среды на основе входящей информации. Чем подробнее модель она может построить, тем больше у нее интеллекта. Модель состоит из информационных объектов, объект это то, что определяется как "одно и то же" в разные моменты времени. Вот эта способность определять "одно и то же", это самое важное. вчера в 20:39 0 Интеллект можно определить и так. Но в таком определении ИИ и СИИ одно и то же и вопрос только в «мощности». Я объясняю, что есть еще и смысл. вчера в 20:49 +1 Нет. Вы пишете "Простой ИИ строится на использовании сущностей, заданных определениями. Отсюда классы, кластеры, тезаурусы". Классы и кластеры — это модель, заложенная программистом. Сильный ИИ должен строить эту модель сам по входящей информации. СИИ, который может пройти тест Тьюринга — это, в первую очередь, интеллект, оперирующий смыслом. Собака не сможет пройти тест Тьюринга, но у нее вполне себе сильный И. А некоторые боты проходят некоторые вариации теста Тьюринга, но смысла они не понимают. Смысл это собственно и есть активация некоторого элемента модели. Ну или вернее сказать, они понимают только в рамках того смысла, который в них заложен извне разработчиком. вчера в 21:10 –1 Собака не проходит, а человек проходит. В том и суть. Вариации не считаются. Смысл теста в том и состоит, чтобы пройти его без «вариаций». сегодня в 03:50 0 А какую цель преследует Объект (или, по-вашему, Система), строя модели? Для чего все это? вчера в 22:13 +1 Очень длинный поток сознания, что хотели сказать — так до конца и не понятно. Вы вроде бы верно говорите, что философы не определились (и вряд ли определятся), что такое "смысл", но потом излагаете одну определенную теорию смысла (какую именно, често не скажу — сам не осилил статью), как будто там вообще не о чем спорить. Даже великий и могучий GPT3 является, по сути, огромным генератором правдоподобного бреда и даже близко не приближается к пониманию того, что он генерирует. Я согласен с этим только если выставить исключительно высокую планку для того, что есть "понимание". Такую высокую, что сама ваша статья (и заодно этот мой комментарий) ее не проходят, а по сути являются "сгенерированным бредом". Я бы сказал, что 80% людей в мире в принципе не способны ни к какому "пониманию" выше даже GPT-3, еще 19% иногда говорят и пишут что-то на уровне GPT-4/GPT-5 (условно, я бы занес нас и наши тут рассуждения в эту категорию), и не более 1-2% действительно могут создавать новые смыслы (или находить их в Платоновском мире — как хотите). Ваш подход к сильному ИИ выглядит слишком зацикленным на языке. Самые сильные ученые и инженеры всегда задействуют "визуальную прошивку" также известную как правое полушарие. Но у меня есть подозрение, что самый простой путь к сильному ИИ — это снести язык и дать ИИ прийти к полностью собственной системе паттернов. Учить сильный ИИ языку, — наверное, можно, но это все еще в духе Deep Blue, а не Alpha Zero. в том, что весь наш язык сильному ИИ будет не нужен, и даже мешать. Но мы вряд ли пойдем по этому пути, во-первых, потому что такой удар будет действительно слишком болезненным для нас, во-вторых, потому что у такого ИИ (возможно) будут проблемы со взаимодействием с человеком, и, в целом, с explainability. вчера в 23:10 0 Вот да, я про в эту сторону ходить, да и то, наверное, не выйдет, потому что у машины нет цветовой дифференциации штанов цели, ей всё это незачем. Ей ни жрать, ни любить не надо, ни от хищников спасаться. Ей даже пофигу, если её выключат. Более того, она даже не догадывается, что ей пофигу. Да и догадываться она тоже не умеет. :) вчера в 22:20 0 «Человек взаимодействует с одним компьютером и одним человеком. На основании ответов на вопросы он должен определить, с кем он разговаривает: с человеком или компьютерной программой. Задача компьютерной программы — ввести человека в заблуждение, заставив сделать неверный выбор».> Насколько я знаю тест Тьюринга давно опровергнут. Эксперимент проводился в больнице. В качестве врача выступала программа, которая через телетайп общалась в больными. Так вот практически все больные ответили, что такого внимательного, хорошего доктора они не встречали. И ларчик здесь открывается просто. Например. вопрос: — Больной, что вас беспокоит или болит. Ответ: доктор у меня болит голова. Доктор: а как давно болит голова? и т.д. Выделены ключевые слова, ответы разбавлены словами внимания и т.д. На выходе идеальный, с точки зрения больного, доктор. Хотя с точки медицины машина ничего и не предлагала. Так что же такое СИС — сильный искусственный интеллект? С чем сравнивать? вчера в 22:51 +2 Насколько я знаю тест Тьюринга давно опровергнут. Эксперимент проводился в больнице То что вы описываете, не является классическим тестом Тьюринга. Экспериментатор должен целенаправленно разоблачать бота. А так, можно принять звонок от робота (например из банка) с каким-то оповещением и из-за того, что абонент не понял, что ему звонил робот, а не человек, решить, что и здесь тест Тьюринга пройден. вчера в 23:06 0 ‹offtop›, но туда же: лично у меня участились звонки из банков с хорошо поставленными диалогами, мне задают вопросы, выдерживают паузы, продолжают рассказывать и рекламировать. Либо я тихо говорю (вряд ли) или мало говорю (ещё врядлее), но меня эти товарищи не слушают, и продолжают, как ни в чём ни бывало, даже если я на них ору. Я сделал вывод, что мне звонит робот и тупо проигрывает начитанную заранее запись с выдержанными паузами и т.п. Т.е., даже не робот, а вообще опустились. ‹/offtop› сегодня в 00:31 0 qw1 ответил исчерпывающе сегодня в 00:38 +1 Последнее видео отвечает на вопрос «кто виноват» (конечно же, определение, убившее смысл), но не отвечает на вопрос «что делать». Я этот ролик воспринимаю пораженьческим, потому что любое программирование, и, в более широком смысле, любая инженерия, это работа с формальными системами. По тону ролика, ничего хорошего из этого не выйдет, истина только в философском словоблудии. Где-то в середине статьи автор сам бросается в программирование трактовок и моделирование ситуаций в контекстах. Разве тут он сам не создаёт убийственное определение? сегодня в 00:48 +1 Ролик показывает часть проблемы. Конечно, определения важны. И сила в гармоничном сочетании смысла и определений. Но это отдельная тема. сегодня в 04:31 0 Понимание — это не свечение внутренней неонки, отражаемое в глазах, а просто адекватное поведение, вызубренное поведение. Другого не бывает. У человека нет никакой антикитайской комнаты. Все просто. Гипотеза о существовании антикитайской (некитайской) комнаты у человека в голове ложна. Автору не хватает знаний в анализе данных, хотя бы про обобщающую способность (генерализацию) прочитал бы. Философня все это, смешанная с ложными умозрительными концепциями. сегодня в 05:33 0 Понимание — это не свечение внутренней неонки, отражаемое в глазах, а просто адекватное поведение, вызубренное поведение. Осталось только узнать кто это адекватное поведение вложил в человека. Креационизм получается однако. сегодня в 06:31 0 Еще раз: у меня исключительно прагматика, никакого креационизма: понимание — это вызубренное поведение. Научили тебя (родители, школа, университет, самообучение), умеешь повторять — значит понимаешь. Тонкость в том, что есть такая штука как обобщение (генерализация), когда по одним обучающим примером закрывается ряд похожих примеров. Нет необходимости обучать сложению чисел, прогоняя через сумматор все возможные комбинации чисел. Достаточно показать несколько, а лучше тысячу примеров. Но автор статьи несет ахинею по этому поводу, он некомпетентен. С генерализацией работают искусственные нейросети и биологические нейросети, никакой принципиальной разницы тут нет. Представление о том, что понимание — это некоторое свечение внутренней неонки, связано с ложным умозрением следующего характера: когда мы выполняем некоторое простое вызубренное действие, мы можем потенциально выполнить ряд более сложных действий (анализ, синтез и т.п.). Однако достаточным и необходимым условием наличия понимания является вызубренное действие, а более сложные действия — это понимание более сложных вещей. И тут надо определиться, а оценку понимания чего вы хотите сделать. Если GPT-3 неадекватно генерирует текст, то она просто не понимает данную тему, но это не означает, что она не разбирается в других темах. Нельзя понимание оценивать глобально, нужно смотреть конкретные выхлопы, как на экзамене. Но вы можете оценить точечно много раз и вывести среднюю оценку. Но сказать, что GPT-3 не понимает — нельзя, она отлично справляется во многих случаях, т.е. она что-то понимает. сегодня в 07:57 0 То, что для одного бред, для другого может иметь смысл, ведь ключи дешифровки в голове у всех разные. Есть лишь общий шаблон ключа, который помогает нам всем удерживаться в одном контексте. Или вдруг для той же Энигмы есть два ключа, которые дают человекочитаемый текст? сегодня в 08:04 0 Меня всегда удивляет, когда сравнивают ИИ и человеческий разум. На минуточку, чтобы получился «естественный интеллект» понадобились сотни тысяч поколений работы генетического алгоритма с огромными популяциями, где каждый агент в популяции имеет сложность, которая и не снилась современной вычислительной технике. Чтобы сформировать сознание человеку нужно 20 лет непрерывного 24/7 обучения на бесконечно разнообразном датасете, который есть реальный мир. Прямо сейчас обучается почти 8 млрд. агентов, нейронная сеть каждого из которых многократно сложнее, чем все, что может дать современный датасайнс. Это ответ эволюции на «комбинаторный взрыв». Меня знатно бомбит, когда кто-то критикует современные достижения в области ИИ. Голосовые ассистенты ошибаются? GPT-3 несет бред? Автопилот теслы попал в аварию? Пару десятков лет ничего этого не было вообще. Я просто в восторге от того, чего удалось достичь за последние годы в области ИИ! И с каждым годом этот восторг только растет. То, что можно просто задать вопрос смартфону голосом и получить ответ, это так естественно, но расскажи об этом мне, 15-летнему школьнику, который потратил 2 недели, пытаясь обучить Dragon Dictate распознавать мой голос (безуспешно), и я тогда бы не поверил. Для меня это просто невероятно круто, что все это появилось при моей жизни, я и с восторгом и замиранием сердца смотрю в будущее не в силах представить, что же будет дальше! Только могут оставлять комментарии. , пожалуйста. Что обсуждают 35,8k 4,3k 5,4k 104k Мегапост 17,5k 3,7k 9,4k 14,4k Мегапост 31,9k 33,5k 104k 22,2k Подборка Самое читаемое +49 17,5k 53 +111 71k 65 +52 14,4k 58 +20 14,2k 2 Мегапост +218 104k 83 +111 71k 65 +45 66,6k 144 +62 36,6k 58 Подборка +231 252k 446 +56 213k 112 +592 209k 505 +62 174k 111 Подборка Ваш аккаунт Разделы Информация Услуги © 2006 – 2021 «» Настройка языка Интерфейс Русский English Язык публикаций Русский Английский Сохранить настройки